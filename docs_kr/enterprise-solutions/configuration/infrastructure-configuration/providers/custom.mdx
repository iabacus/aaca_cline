---
title: "커스텀 제공자 구성"
sidebarTitle: "커스텀 제공자"
description: "Cline 배포를 위한 커스텀 OpenAI 호환 제공자를 구성합니다"
---

<Info>
**구성 경로: 자체 호스팅**

이 가이드는 자체 호스팅 배포에서 커스텀 제공자 구성을 다룹니다.
</Info>

Azure OpenAI, 자체 호스팅 추론 서버, 기타 서드파티 서비스 등 OpenAI API 형식을 지원하는 어떤 제공자도 Cline에서 사용할 수 있도록 구성할 수 있습니다.

## 커스텀 제공자란?

커스텀 제공자는 OpenAI API 형식을 구현하는 모든 API를 의미합니다:

- **Azure OpenAI Service**: Microsoft의 관리형 OpenAI 모델
- **vLLM**: 자체 호스팅 추론 서버
- **Ollama**: 로컬 모델 실행기
- **Text Generation Inference (TGI)**: Hugging Face 추론 서버
- **LocalAI**: 로컬 OpenAI API 대체재
- **기타 OpenAI 호환 API**: 사용자 정의 구현체

## 구성 형식

원격 구성 JSON에서 `providerSettings.OpenAiCompatible` 섹션으로 커스텀 제공자를 구성합니다:

```json
{
  "providerSettings": {
    "OpenAiCompatible": {
      "models": [
        {
          "id": "gpt-4-turbo",
          "name": "GPT-4 Turbo"
        }
      ],
      "openAiBaseUrl": "https://your-api.company.com/v1"
    }
  }
}
```

## 구성 필드

| 필드 | 타입 | 설명 | 필수 |
|-------|------|-------------|----------|
| `models` | Array | 모델 구성 목록 | 예 |
| `openAiBaseUrl` | String | API 엔드포인트 기본 URL | 예 |
| `openAiApiKey` | String | 인증용 API 키 | 아니오 |
| `openAiModelId` | String | 기본 모델 식별자 | 아니오 |

### Azure OpenAI 전용 필드

Azure OpenAI의 경우 추가 필드를 사용할 수 있습니다:

| 필드 | 타입 | 설명 |
|-------|------|-------------|
| `azureApiVersion` | String | Azure API 버전(예: `2024-02-15-preview`) |

## 구성 예시

### Azure OpenAI

```json
{
  "providerSettings": {
    "OpenAiCompatible": {
      "models": [
        {
          "id": "gpt-4-turbo",
          "name": "GPT-4 Turbo"
        }
      ],
      "openAiBaseUrl": "https://your-resource.openai.azure.com/openai/deployments/gpt-4-turbo",
      "openAiApiKey": "your-azure-api-key",
      "azureApiVersion": "2024-02-15-preview"
    }
  }
}
```

### 자체 호스팅 vLLM

```json
{
  "providerSettings": {
    "OpenAiCompatible": {
      "models": [
        {
          "id": "meta-llama/Llama-2-70b-chat-hf",
          "name": "Llama 2 70B"
        }
      ],
      "openAiBaseUrl": "http://vllm.company.com:8000/v1"
    }
  }
}
```

### 로컬 Ollama

```json
{
  "providerSettings": {
    "OpenAiCompatible": {
      "models": [
        {
          "id": "codellama",
          "name": "Code Llama"
        }
      ],
      "openAiBaseUrl": "http://localhost:11434/v1"
    }
  }
}
```

### Text Generation Inference (TGI)

```json
{
  "providerSettings": {
    "OpenAiCompatible": {
      "models": [
        {
          "id": "mistralai/Mistral-7B-Instruct-v0.2",
          "name": "Mistral 7B Instruct"
        }
      ],
      "openAiBaseUrl": "http://tgi.company.com:8080/v1",
      "openAiApiKey": "your-tgi-api-key"
    }
  }
}
```

### LocalAI

```json
{
  "providerSettings": {
    "OpenAiCompatible": {
      "models": [
        {
          "id": "gpt-3.5-turbo",
          "name": "Local GPT-3.5"
        }
      ],
      "openAiBaseUrl": "http://localhost:8080/v1"
    }
  }
}
```

### 내부 네트워크(인증 없음)

```json
{
  "providerSettings": {
    "OpenAiCompatible": {
      "models": [
        {
          "id": "custom-model",
          "name": "Custom Model"
        }
      ],
      "openAiBaseUrl": "http://internal.api:8000/v1"
    }
  }
}
```

## 모델 구성

각 모델에는 기본 정보가 필요합니다:

```json
{
  "id": "model-identifier",
  "name": "Display Name",
  "info": {
    "maxTokens": 4096,
    "contextWindow": 128000,
    "supportsImages": true,
    "supportsPromptCache": false
  }
}
```

## 사전 준비

커스텀 제공자를 구성하기 전에 다음이 필요합니다:

1. **API 엔드포인트**: OpenAI 호환 API의 URL
2. **API 키**(필요한 경우): 인증 자격 증명
3. **모델 ID**: 사용 가능한 모델 이름
4. **네트워크 접근**: Cline이 사용되는 위치에서의 연결성

## 문제 해결

**연결 오류**

엔드포인트 접근을 확인하세요:
```bash
curl https://your-api.company.com/v1/models
```

**인증 오류**

API 키로 인증을 테스트하세요:
```bash
curl -H "Authorization: Bearer your-api-key" \
  https://your-api.company.com/v1/models
```

**Model Not Found**

구성의 모델 ID가 API에서 기대하는 값과 일치하는지 확인하세요. 사용 가능한 모델을 확인하려면:
```bash
curl -H "Authorization: Bearer your-api-key" \
  https://your-api.company.com/v1/models
```

**타임아웃 문제**

응답이 느린 경우:
- 네트워크 지연 확인
- 서버 리소스가 충분한지 확인
- 더 빠른 모델 사용 고려

## 제공자 문서

설정 및 배포에 대한 공식 문서:

<CardGroup cols={2}>
  <Card title="Azure OpenAI" icon="microsoft" href="https://learn.microsoft.com/en-us/azure/ai-services/openai/">
    Microsoft의 관리형 OpenAI 서비스
  </Card>
  
  <Card title="vLLM" icon="server" href="https://docs.vllm.ai/">
    고성능 추론 엔진
  </Card>
  
  <Card title="Ollama" icon="download" href="https://ollama.ai/">
    로컬에서 모델 실행
  </Card>
  
  <Card title="Text Generation Inference" icon="code" href="https://huggingface.co/docs/text-generation-inference/">
    Hugging Face 추론 서버
  </Card>
</CardGroup>
