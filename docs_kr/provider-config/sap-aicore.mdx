---
title: "SAP AI Core"
description: "Cline에서 SAP AI Core의 Generative AI Hub LLM 모델을 설정하고 사용하는 방법을 알아보세요."
---

SAP AI Core와 Generative AI Hub는 비용 효율적으로 새로운 비즈니스 프로세스에 LLM과 AI를 통합할 수 있도록 도와줍니다.

**웹사이트:** [SAP Help Portal](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/what-is-sap-ai-core)


<Info>
SAP AI Core와 Generative AI Hub는 SAP BTP의 서비스입니다. 이 절차를 수행하려면 활성 SAP BTP 계약과 `extended` 서비스 플랜이 포함된 SAP AI Core 인스턴스를 가진 하위 계정이 필요합니다(SAP AI Core 서비스 플랜과 기능에 대한 자세한 내용은 [Service Plans 문서](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/service-plans)를 참고하세요).
</Info>

### 서비스 바인딩 받기

1. **접근:** [BTP Cloud Cockpit](https://cockpit.btp.cloud.sap/cockpit)에서 하위 계정으로 이동합니다.
2. **서비스 바인딩 생성:** "Instances and Subscriptions"로 이동하여 SAP AI Core 서비스 인스턴스를 선택하고 Service Bindings > Create를 클릭합니다.
3. **서비스 바인딩 복사:** 서비스 바인딩 값을 복사합니다.

### 지원 모델

SAP AI Core는 많은 모델을 지원하며 계속 확대되고 있습니다.
전체 최신 목록은 [Generative AI Hub 지원 모델 페이지](https://me.sap.com/notes/3437766)를 참고하세요.

### Cline에서 설정하기

1.  **Cline 설정 열기:** Cline 패널의 설정 아이콘(⚙️)을 클릭합니다.
2.  **프로바이더 선택:** "API Provider" 드롭다운에서 "SAP AI Core"를 선택합니다.
3.  **Client Id 입력:** 서비스 바인딩의 `.clientid` 값을 "AI Core Client Id" 필드에 입력합니다.
4.  **Client Secret 입력:** 서비스 바인딩의 `.clientsecret` 값을 "AI Core Client Secret" 필드에 입력합니다.
5.  **Base URL 입력:** 서비스 바인딩의 `.serviceurls.AI_API_URL` 값을 "AI Core Base URL" 필드에 입력합니다.
6.  **Auth URL 입력:** 서비스 바인딩의 `.url` 값을 "AI Core Auth URL" 필드에 입력합니다.
7.  **Resource Group 입력:** 모델 배포가 있는 리소스 그룹을 입력합니다. [Generative AI 모델 배포 생성](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/create-deployment-for-generative-ai-model-in-sap-ai-core)을 참고하세요.
8.  **오케스트레이션 모드 설정:** `extended` 서비스 플랜이 있으면 "Orchestration Mode" 체크박스가 자동으로 표시됩니다.
9.  **모델 선택:** "Model" 드롭다운에서 원하는 모델을 선택합니다.

### 오케스트레이션 모드 vs 네이티브 API

**오케스트레이션 모드:**
- **간소화된 사용:** [Harmonized API](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/harmonized-api)를 사용해 개별 배포 없이 모든 사용 가능한 모델에 접근

**네이티브 API 모드:**
- **수동 배포:** SAP AI Core 서비스 인스턴스에서 모델 배포와 관리를 수동으로 수행해야 함

### 팁과 참고사항

- **서비스 플랜 요구:** Cline에서 LLM을 사용하려면 SAP AI Core `extended` 서비스 플랜이 필요합니다. 다른 서비스 플랜은 Generative AI Hub에 접근할 수 없습니다.

- **오케스트레이션 모드(권장):** 가장 간단한 설정을 위해 오케스트레이션 모드를 활성화하세요. 수동 배포 없이 모든 사용 가능한 모델에 자동으로 접근할 수 있습니다.

- **네이티브 API 모드:** 오케스트레이션 모드에서 지원하지 않는 기능이 필요하거나 AI Core API 직접 접근이 필요한 경우에만 비활성화하세요.

- **네이티브 API 모드 사용 시:**
    -   **모델 선택:** 모델 드롭다운은 두 개의 목록으로 표시됩니다:
        -   **배포된 모델:** 지정한 리소스 그룹에 이미 배포되어 즉시 사용 가능한 모델
        -   **미배포 모델:** 지정한 리소스 그룹에 활성 배포가 없는 모델. SAP AI Core에서 배포를 만들기 전에는 사용할 수 없습니다.
    -   **배포 생성:** 아직 배포되지 않은 모델을 사용하려면 SAP AI Core 서비스 인스턴스에서 배포를 생성해야 합니다. 자세한 방법은 [Generative AI 모델 배포 생성](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/create-deployment-for-generative-ai-model-in-sap-ai-core)을 참고하세요.

#### OpenAI 모델의 Reasoning Effort 설정

SAP AI Core에서 OpenAI 추론 모델(o1, o3, o3-mini, o4-mini 등)을 사용할 때 성능과 비용의 균형을 위해 Reasoning Effort를 조정할 수 있습니다:

1. **Cline 설정 열기:** Cline 패널의 설정 아이콘(⚙️)을 클릭합니다.
2. **Features로 이동:** 설정의 "Features" 섹션으로 이동합니다.
3. **OpenAI Reasoning Effort 찾기:** "OpenAI Reasoning Effort" 설정을 찾습니다.
4. **Effort 레벨 선택:** 다음 중 선택합니다:
   - **Low:** 토큰 사용량이 낮고 응답이 빠르며, 단순 작업에 적합
   - **Medium:** 대부분의 작업에 적합한 균형형
   - **High:** 더 깊은 분석과 높은 토큰 사용량으로 복잡한 추론 작업에 적합

<Note>
이 설정은 SAP AI Core를 통해 배포된 OpenAI 추론 모델(o1, o3, o3-mini, o4-mini, gpt-5 등)에서만 적용됩니다. 다른 모델은 이 설정을 무시합니다.
</Note>
